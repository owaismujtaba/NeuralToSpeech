# NeuroIncept Decoder

## Technology Stack

![absl-py](https://img.shields.io/badge/absl--py-2.1.0-blue.svg)
![arrow](https://img.shields.io/badge/arrow-1.3.0-lightgrey.svg)
![astunparse](https://img.shields.io/badge/astunparse-1.6.3-lightgrey.svg)
![h5py](https://img.shields.io/badge/h5py-3.11.0-lightgrey.svg)
![hdmf](https://img.shields.io/badge/hdmf-3.14.4-lightgrey.svg)
![keras](https://img.shields.io/badge/keras-3.5.0-lightgrey.svg)
![kiwisolver](https://img.shields.io/badge/kiwisolver-1.4.7-lightgrey.svg)
![libclang](https://img.shields.io/badge/libclang-18.1.1-lightgrey.svg)
![numpy](https://img.shields.io/badge/numpy-1.26.4-lightgrey.svg)
![pandas](https://img.shields.io/badge/pandas-2.2.2-lightgrey.svg)
![pillow](https://img.shields.io/badge/pillow-10.4.0-lightgrey.svg)
![pynwb](https://img.shields.io/badge/pynwb-2.8.2-lightgrey.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.5.1-lightgrey.svg)
![scipy](https://img.shields.io/badge/scipy-1.14.1-lightgrey.svg)
![seaborn](https://img.shields.io/badge/seaborn-0.13.2-lightgrey.svg)
![six](https://img.shields.io/badge/six-1.16.0-lightgrey.svg)
![tensorboard](https://img.shields.io/badge/tensorboard-2.17.1-lightgrey.svg)
![tensorboard-data-server](https://img.shields.io/badge/tensorboard--data--server-0.7.2-lightgrey.svg)
![tensorflow](https://img.shields.io/badge/tensorflow-2.17.0-lightgrey.svg)
![tensorflow-io-gcs-filesystem](https://img.shields.io/badge/tensorflow--io--gcs--filesystem-0.37.1-lightgrey.svg)


This project focuses on processing, reconstructing, and visualizing audio data. It is designed to work with datasets that involve audio recordings from multiple participants, performing tasks such as feature extraction, audio reconstruction, and generating visualizations to assess performance.

## Project Structure

- **Feature Extraction**: Extracts important features from the audio recordings of multiple participants.
- **Audio Reconstruction**: Recreates audio signals from the extracted features using the custom `AudioReconstructor` class.
- **Visualization**: Generates plots to visualize correlations, STGI (Short-Time Geometric Image) results, and model training history.

## Preprocessing Pipeline

Below is an illustration of the preprocessing pipeline used in the project:

![Preprocessing Pipeline](Images/dataprocessing.PNG)

## Model Architecture

The custom model architecture used for audio reconstruction is shown below:

![Model Architecture](Images/model.png)

## Configuration

The project is configured using the `config` file located in `src/config.py`. The key parameters include:

- **num_jobs**: Number of parallel jobs for processing (default: 20)
- **extract_features**: Whether to run feature extraction (`True` or `False`)
- **construct**: Whether to run the audio reconstruction process (`True` or `False`)
- **visualization**: Whether to generate visualizations (`True` or `False`)
- **current_dir**: The current working directory.
- **dataset_dir**: Directory containing the dataset (`SingleWordProductionDutch-iBIDS`).
- **features_dir**: Directory where extracted features are stored.
- **results_dir**: Directory where the results (e.g., reconstructions, plots) will be saved.
- **no_of_mel_spectrograms**: The number of mel spectral Bins (default: 128).
- **epochs**: Number of epochs for model training (default: 100).
- **batch_size**: Batch size for model training (default: 128).
- **num_folds**: Number of folds for cross-validation (default: 10).

## How to Run

1. **Install Dependencies**: Make sure to install the required Python libraries before running the project. You can install them using:
    ```bash
    pip install -r requirements.txt
    ```

2. **Configure the Project**: Modify the settings in `src/config.py` to fit your requirements. For example, set `extract_features`, `construct`, or `visualization` to `True` depending on the tasks you want to perform.

3. **Run the Script**:
    - To run the feature extraction, reconstruction, and visualization:
    ```bash
    python main.py
    ```

## Visualization

If `visualization` is set to `True` in the configuration file, the project will generate the following plots:

- **Correlation Plot**: Shows the bar plot for correlation between the predicted spectrograms by NeuroIncept Decoder Model and original spectrograms for all subjects .
- **STGI Plot**: Displays Bar Plot of STGI metric for all Subjects.
- **History Plot**: Plots the history of the model's training process, Validation loss.
- **Spectrograms Plot**: Spectrograms generated by various model architectures.

## Dataset

The project uses a dataset called `SingleWordProductionDutch-iBIDS`, which should be placed in the directory specified in `config.py` under `dataset_dir`.




